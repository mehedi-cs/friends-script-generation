{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accomplished-psychiatry",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:40.772269Z",
     "iopub.status.busy": "2021-04-08T11:53:40.770805Z",
     "iopub.status.idle": "2021-04-08T11:53:43.981061Z",
     "shell.execute_reply": "2021-04-08T11:53:43.979762Z"
    },
    "papermill": {
     "duration": 3.229304,
     "end_time": "2021-04-08T11:53:43.981237",
     "exception": false,
     "start_time": "2021-04-08T11:53:40.751933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "data_dir = '../input/friends-tv-series-screenplay-script/'\n",
    "text = \"\"\n",
    "for file in glob.glob(data_dir+\"*.txt\"):\n",
    "    f = open(file, 'r')\n",
    "    text += f.read()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afraid-frequency",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:44.020176Z",
     "iopub.status.busy": "2021-04-08T11:53:44.019448Z",
     "iopub.status.idle": "2021-04-08T11:53:44.023231Z",
     "shell.execute_reply": "2021-04-08T11:53:44.023669Z"
    },
    "papermill": {
     "duration": 0.025852,
     "end_time": "2021-04-08T11:53:44.023803",
     "exception": false,
     "start_time": "2021-04-08T11:53:43.997951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The One With The Stain\\nWritten by: R. Lee Fleming, Jr.\\n\\n\\n[Scene: Monica and Chandler's, Chandler is sitting in the living room as Monica enters.]\\n\\nMonica: Hey.\\n\\nChandler: Hey.\\n\\n(Monica notices something.)\\n\\nMonica: Oh my God! You cleaned! (Gasps) Look at these floors! You did the windows! Oh, I have been begging you for months and you did! You cleaned! And nagging works!\\n\\nChandler: Y’know uh, I didn’t actually do this.\\n\\nMonica: Oh no, was I cleaning in my sleep again?\\n\\nChandler: No, it wasn’t you\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excited-roots",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:44.058259Z",
     "iopub.status.busy": "2021-04-08T11:53:44.057506Z",
     "iopub.status.idle": "2021-04-08T11:53:44.169634Z",
     "shell.execute_reply": "2021-04-08T11:53:44.168741Z"
    },
    "papermill": {
     "duration": 0.130937,
     "end_time": "2021-04-08T11:53:44.169782",
     "exception": false,
     "start_time": "2021-04-08T11:53:44.038845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "folder_name = \"../input/friends-tv-series-screenplay-script/\"\n",
    "for f in glob.glob(folder_name + '/*.txt'):\n",
    "    temp = open(f,'r')    \n",
    "    text += temp.read()\n",
    "    temp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "plain-lafayette",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:44.223944Z",
     "iopub.status.busy": "2021-04-08T11:53:44.223133Z",
     "iopub.status.idle": "2021-04-08T11:53:44.227501Z",
     "shell.execute_reply": "2021-04-08T11:53:44.227098Z"
    },
    "papermill": {
     "duration": 0.042574,
     "end_time": "2021-04-08T11:53:44.227609",
     "exception": false,
     "start_time": "2021-04-08T11:53:44.185035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lines 0 to 25:\n",
      "The One With The Stain\n",
      "Written by: R. Lee Fleming, Jr.\n",
      "\n",
      "\n",
      "[Scene: Monica and Chandler's, Chandler is sitting in the living room as Monica enters.]\n",
      "\n",
      "Monica: Hey.\n",
      "\n",
      "Chandler: Hey.\n",
      "\n",
      "(Monica notices something.)\n",
      "\n",
      "Monica: Oh my God! You cleaned! (Gasps) Look at these floors! You did the windows! Oh, I have been begging you for months and you did! You cleaned! And nagging works!\n",
      "\n",
      "Chandler: Y’know uh, I didn’t actually do this.\n",
      "\n",
      "Monica: Oh no, was I cleaning in my sleep again?\n",
      "\n",
      "Chandler: No, it wasn’t you.\n",
      "\n",
      "Monica: Well then who?\n",
      "\n",
      "Chandler: I got a maid. Yay!\n",
      "\n",
      "Monica: (shocked) I hope by maid you mean mistress, because if some other woman was here cleaning then…\n"
     ]
    }
   ],
   "source": [
    "view_line_range = (0, 25)\n",
    "print('The lines {} to {}:'.format(*view_line_range))\n",
    "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "universal-librarian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:44.346044Z",
     "iopub.status.busy": "2021-04-08T11:53:44.263540Z",
     "iopub.status.idle": "2021-04-08T11:53:44.572145Z",
     "shell.execute_reply": "2021-04-08T11:53:44.571363Z"
    },
    "papermill": {
     "duration": 0.329344,
     "end_time": "2021-04-08T11:53:44.572349",
     "exception": false,
     "start_time": "2021-04-08T11:53:44.243005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Total # of Unique Words:  55817\n",
      "Total # of Lines:  140754\n",
      "Average number of words in each line:  6.237584722281428\n"
     ]
    }
   ],
   "source": [
    "print('Dataset Stats')\n",
    "unique_words = len ({word for word in text.split()})\n",
    "print(\"Total # of Unique Words: \",unique_words)\n",
    "lines = text.split('\\n')\n",
    "print(\"Total # of Lines: \",len(lines))\n",
    "avg_words_perline = [len(line.split()) for line in lines]\n",
    "print(\"Average number of words in each line: \", np.average(avg_words_perline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-cooking",
   "metadata": {
    "papermill": {
     "duration": 0.018218,
     "end_time": "2021-04-08T11:53:44.609397",
     "exception": false,
     "start_time": "2021-04-08T11:53:44.591179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "static-delivery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:44.919825Z",
     "iopub.status.busy": "2021-04-08T11:53:44.918347Z",
     "iopub.status.idle": "2021-04-08T11:53:44.920777Z",
     "shell.execute_reply": "2021-04-08T11:53:44.920351Z"
    },
    "papermill": {
     "duration": 0.293642,
     "end_time": "2021-04-08T11:53:44.920905",
     "exception": false,
     "start_time": "2021-04-08T11:53:44.627263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "freq_word = Counter(text)\n",
    "vocab_sorted = sorted(freq_word, key = freq_word.get, reverse = True)\n",
    "int_to_vocab = {i : word for i, word in enumerate(vocab_sorted)}\n",
    "vocab_to_int = {word : i for i, word in int_to_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sticky-saturday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:44.958224Z",
     "iopub.status.busy": "2021-04-08T11:53:44.957720Z",
     "iopub.status.idle": "2021-04-08T11:53:44.961585Z",
     "shell.execute_reply": "2021-04-08T11:53:44.961188Z"
    },
    "papermill": {
     "duration": 0.024206,
     "end_time": "2021-04-08T11:53:44.961709",
     "exception": false,
     "start_time": "2021-04-08T11:53:44.937503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pun_dic = {\n",
    "        '.': '||period||',\n",
    "        ',': '||comma||',\n",
    "        '\"': '||quotation_mark||',\n",
    "        ';': '||semicolon||',\n",
    "        '!': '||exclamation_mark||',\n",
    "        '?': '||question_mark||',\n",
    "        '(': '||left_parentheses||',\n",
    "        ')': '||right_Parentheses||',\n",
    "        '-': '||dash||',\n",
    "        '\\n': '||return||'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "right-homework",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:45.000931Z",
     "iopub.status.busy": "2021-04-08T11:53:45.000309Z",
     "iopub.status.idle": "2021-04-08T11:53:45.004031Z",
     "shell.execute_reply": "2021-04-08T11:53:45.003606Z"
    },
    "papermill": {
     "duration": 0.026168,
     "end_time": "2021-04-08T11:53:45.004143",
     "exception": false,
     "start_time": "2021-04-08T11:53:44.977975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = text[57:] # dropped the first two line( notice )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prepared-duplicate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:45.151671Z",
     "iopub.status.busy": "2021-04-08T11:53:45.135062Z",
     "iopub.status.idle": "2021-04-08T11:53:45.358055Z",
     "shell.execute_reply": "2021-04-08T11:53:45.357541Z"
    },
    "papermill": {
     "duration": 0.337667,
     "end_time": "2021-04-08T11:53:45.358177",
     "exception": false,
     "start_time": "2021-04-08T11:53:45.020510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, token in pun_dic.items(): \n",
    "    text = text.replace(key, ' {} '.format(token))\n",
    "text = text.lower()\n",
    "text = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quarterly-financing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:45.605611Z",
     "iopub.status.busy": "2021-04-08T11:53:45.603901Z",
     "iopub.status.idle": "2021-04-08T11:53:45.606355Z",
     "shell.execute_reply": "2021-04-08T11:53:45.606802Z"
    },
    "papermill": {
     "duration": 0.231435,
     "end_time": "2021-04-08T11:53:45.606955",
     "exception": false,
     "start_time": "2021-04-08T11:53:45.375520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "SPECIAL_WORDS = {'PADDING': '<PAD>'}\n",
    "L_text = text + list(SPECIAL_WORDS.values())\n",
    "\n",
    "freq_word = Counter(L_text)\n",
    "vocab_sorted = sorted(freq_word, key = freq_word.get, reverse = True)\n",
    "int_to_vocab = {i : word for i, word in enumerate(vocab_sorted)}\n",
    "vocab_to_int = {word : i for i, word in int_to_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "uniform-miracle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:45.653494Z",
     "iopub.status.busy": "2021-04-08T11:53:45.648346Z",
     "iopub.status.idle": "2021-04-08T11:53:45.757053Z",
     "shell.execute_reply": "2021-04-08T11:53:45.756593Z"
    },
    "papermill": {
     "duration": 0.133149,
     "end_time": "2021-04-08T11:53:45.757172",
     "exception": false,
     "start_time": "2021-04-08T11:53:45.624023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "int_text = [vocab_to_int[word] for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "distinguished-apparel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:46.450370Z",
     "iopub.status.busy": "2021-04-08T11:53:46.449729Z",
     "iopub.status.idle": "2021-04-08T11:53:46.460440Z",
     "shell.execute_reply": "2021-04-08T11:53:46.459002Z"
    },
    "papermill": {
     "duration": 0.686615,
     "end_time": "2021-04-08T11:53:46.460942",
     "exception": false,
     "start_time": "2021-04-08T11:53:45.774327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-input",
   "metadata": {
    "papermill": {
     "duration": 0.037374,
     "end_time": "2021-04-08T11:53:46.529122",
     "exception": false,
     "start_time": "2021-04-08T11:53:46.491748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fallen-recommendation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:46.606057Z",
     "iopub.status.busy": "2021-04-08T11:53:46.605235Z",
     "iopub.status.idle": "2021-04-08T11:53:46.609794Z",
     "shell.execute_reply": "2021-04-08T11:53:46.610406Z"
    },
    "papermill": {
     "duration": 0.050739,
     "end_time": "2021-04-08T11:53:46.610592",
     "exception": false,
     "start_time": "2021-04-08T11:53:46.559853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "def get_dataloader(text, seq_length, batch_size):\n",
    "    batch_num = len(text)//batch_size\n",
    "    batch_words = text[: (batch_num * batch_size)]\n",
    "    \n",
    "    feature, target = [],[]\n",
    "    target_len = len(batch_words[:-seq_length])\n",
    "    \n",
    "    for i in range(0, target_len):\n",
    "        feature.append(batch_words[i: i + seq_length])\n",
    "        target.append(batch_words[i + seq_length])\n",
    "    \n",
    "    target_tensors = torch.from_numpy(np.array(target))\n",
    "    feature_tensors = torch.from_numpy(np.array(feature))\n",
    "    \n",
    "    data = TensorDataset(feature_tensors, target_tensors)\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(data, batch_size = batch_size, shuffle = True)\n",
    "    \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "grand-muscle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:46.716317Z",
     "iopub.status.busy": "2021-04-08T11:53:46.706221Z",
     "iopub.status.idle": "2021-04-08T11:53:46.720818Z",
     "shell.execute_reply": "2021-04-08T11:53:46.721756Z"
    },
    "papermill": {
     "duration": 0.083624,
     "end_time": "2021-04-08T11:53:46.721941",
     "exception": false,
     "start_time": "2021-04-08T11:53:46.638317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.3):\n",
    "        super(RNN,self).__init__()\n",
    "        self.n_layers  = n_layers\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Model Layers\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout = dropout, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, nn_input, hidden):\n",
    "        batch_size = nn_input.size(0)\n",
    "        nn_input = nn_input.long()\n",
    "        \n",
    "        embed_out = self.embedding(nn_input)\n",
    "        lstm_out, hidden = self.lstm(embed_out, hidden)\n",
    "        \n",
    "        \n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_out = self.fc(lstm_out)\n",
    "        \n",
    "        lstm_out = lstm_out.view(batch_size, -1, self.output_size)\n",
    "        lstm_output = lstm_out[:, -1]\n",
    "        \n",
    "        return lstm_output, hidden\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            hidden = (weight.new(self.n_layers, batch_size , self.hidden_dim).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size , self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size , self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size , self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "secure-positive",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:46.799011Z",
     "iopub.status.busy": "2021-04-08T11:53:46.798264Z",
     "iopub.status.idle": "2021-04-08T11:53:46.801448Z",
     "shell.execute_reply": "2021-04-08T11:53:46.802043Z"
    },
    "papermill": {
     "duration": 0.051533,
     "end_time": "2021-04-08T11:53:46.802221",
     "exception": false,
     "start_time": "2021-04-08T11:53:46.750688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
    "    if (train_on_gpu):\n",
    "        inp, target = inp.cuda(), target.cuda()\n",
    "    \n",
    "    hidden = tuple([i.data for i in hidden])\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    out, hidden = rnn(inp, hidden)\n",
    "    \n",
    "    loss = criterion(out, target)\n",
    "    loss.backward()\n",
    "    \n",
    "    clip = 5\n",
    "    \n",
    "    nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "searching-fifth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:46.889890Z",
     "iopub.status.busy": "2021-04-08T11:53:46.889142Z",
     "iopub.status.idle": "2021-04-08T11:53:46.893118Z",
     "shell.execute_reply": "2021-04-08T11:53:46.894500Z"
    },
    "papermill": {
     "duration": 0.056182,
     "end_time": "2021-04-08T11:53:46.894690",
     "exception": false,
     "start_time": "2021-04-08T11:53:46.838508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
    "    batch_losses = []\n",
    "    rnn.train()\n",
    "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
    "    for epoch_i in range(1, n_epochs + 1):\n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        \n",
    "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if(batch_i > n_batches):\n",
    "                break\n",
    "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
    "            \n",
    "            batch_losses.append(loss)\n",
    "            if batch_i % show_every_n_batches == 0:\n",
    "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
    "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
    "                batch_losses = []\n",
    "\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spare-cancer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:47.169108Z",
     "iopub.status.busy": "2021-04-08T11:53:46.986768Z",
     "iopub.status.idle": "2021-04-08T11:53:52.474176Z",
     "shell.execute_reply": "2021-04-08T11:53:52.474700Z"
    },
    "papermill": {
     "duration": 5.546118,
     "end_time": "2021-04-08T11:53:52.474892",
     "exception": false,
     "start_time": "2021-04-08T11:53:46.928774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = 8\n",
    "batch_size = 256\n",
    "train_loader = get_dataloader(int_text, sequence_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pointed-glossary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:52.515816Z",
     "iopub.status.busy": "2021-04-08T11:53:52.515107Z",
     "iopub.status.idle": "2021-04-08T11:53:52.518059Z",
     "shell.execute_reply": "2021-04-08T11:53:52.517593Z"
    },
    "papermill": {
     "duration": 0.02477,
     "end_time": "2021-04-08T11:53:52.518172",
     "exception": false,
     "start_time": "2021-04-08T11:53:52.493402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = 25\n",
    "lr = 0.0003\n",
    "vocab_size = len(vocab_to_int)\n",
    "output_size = len(vocab_to_int)\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 3\n",
    "show_every_n_batches = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "weekly-phoenix",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T11:53:52.561956Z",
     "iopub.status.busy": "2021-04-08T11:53:52.561346Z",
     "iopub.status.idle": "2021-04-08T13:25:12.394071Z",
     "shell.execute_reply": "2021-04-08T13:25:12.393420Z"
    },
    "papermill": {
     "duration": 5479.858521,
     "end_time": "2021-04-08T13:25:12.394254",
     "exception": false,
     "start_time": "2021-04-08T11:53:52.535733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 25 epoch(s)...\n",
      "Epoch:    1/25    Loss: 5.754349414825439\n",
      "\n",
      "Epoch:    1/25    Loss: 5.100264770507812\n",
      "\n",
      "Epoch:    1/25    Loss: 4.896413414001465\n",
      "\n",
      "Epoch:    1/25    Loss: 4.727351550102234\n",
      "\n",
      "Epoch:    1/25    Loss: 4.613761981010437\n",
      "\n",
      "Epoch:    1/25    Loss: 4.53656585264206\n",
      "\n",
      "Epoch:    1/25    Loss: 4.466126928329468\n",
      "\n",
      "Epoch:    1/25    Loss: 4.429315262317657\n",
      "\n",
      "Epoch:    1/25    Loss: 4.380247849941254\n",
      "\n",
      "Epoch:    1/25    Loss: 4.333065752506256\n",
      "\n",
      "Epoch:    2/25    Loss: 4.253175471886106\n",
      "\n",
      "Epoch:    2/25    Loss: 4.223149055957794\n",
      "\n",
      "Epoch:    2/25    Loss: 4.220769937515259\n",
      "\n",
      "Epoch:    2/25    Loss: 4.1931964864730835\n",
      "\n",
      "Epoch:    2/25    Loss: 4.1708382883071895\n",
      "\n",
      "Epoch:    2/25    Loss: 4.165093412399292\n",
      "\n",
      "Epoch:    2/25    Loss: 4.153962570667267\n",
      "\n",
      "Epoch:    2/25    Loss: 4.13478156709671\n",
      "\n",
      "Epoch:    2/25    Loss: 4.120389589309692\n",
      "\n",
      "Epoch:    2/25    Loss: 4.1005942897796634\n",
      "\n",
      "Epoch:    3/25    Loss: 4.045365345912794\n",
      "\n",
      "Epoch:    3/25    Loss: 4.010773869037628\n",
      "\n",
      "Epoch:    3/25    Loss: 4.026793962955475\n",
      "\n",
      "Epoch:    3/25    Loss: 4.0045544586181645\n",
      "\n",
      "Epoch:    3/25    Loss: 4.005099697589874\n",
      "\n",
      "Epoch:    3/25    Loss: 4.005433507919312\n",
      "\n",
      "Epoch:    3/25    Loss: 4.008727954864502\n",
      "\n",
      "Epoch:    3/25    Loss: 4.008052698612213\n",
      "\n",
      "Epoch:    3/25    Loss: 3.98351291179657\n",
      "\n",
      "Epoch:    3/25    Loss: 3.9647567811012268\n",
      "\n",
      "Epoch:    4/25    Loss: 3.9188481429716906\n",
      "\n",
      "Epoch:    4/25    Loss: 3.9107010583877564\n",
      "\n",
      "Epoch:    4/25    Loss: 3.9042570128440857\n",
      "\n",
      "Epoch:    4/25    Loss: 3.8943290462493896\n",
      "\n",
      "Epoch:    4/25    Loss: 3.90759184217453\n",
      "\n",
      "Epoch:    4/25    Loss: 3.908890986919403\n",
      "\n",
      "Epoch:    4/25    Loss: 3.8868994426727297\n",
      "\n",
      "Epoch:    4/25    Loss: 3.902244488239288\n",
      "\n",
      "Epoch:    4/25    Loss: 3.9051199140548705\n",
      "\n",
      "Epoch:    4/25    Loss: 3.891147503852844\n",
      "\n",
      "Epoch:    5/25    Loss: 3.838532070280723\n",
      "\n",
      "Epoch:    5/25    Loss: 3.844432626724243\n",
      "\n",
      "Epoch:    5/25    Loss: 3.842430791378021\n",
      "\n",
      "Epoch:    5/25    Loss: 3.8266372427940367\n",
      "\n",
      "Epoch:    5/25    Loss: 3.822684352874756\n",
      "\n",
      "Epoch:    5/25    Loss: 3.822851041793823\n",
      "\n",
      "Epoch:    5/25    Loss: 3.819218398571014\n",
      "\n",
      "Epoch:    5/25    Loss: 3.8220370559692385\n",
      "\n",
      "Epoch:    5/25    Loss: 3.8287957344055177\n",
      "\n",
      "Epoch:    5/25    Loss: 3.8340324749946593\n",
      "\n",
      "Epoch:    6/25    Loss: 3.7616203984463743\n",
      "\n",
      "Epoch:    6/25    Loss: 3.777259301185608\n",
      "\n",
      "Epoch:    6/25    Loss: 3.769691462993622\n",
      "\n",
      "Epoch:    6/25    Loss: 3.76550723695755\n",
      "\n",
      "Epoch:    6/25    Loss: 3.7779531331062315\n",
      "\n",
      "Epoch:    6/25    Loss: 3.775134191036224\n",
      "\n",
      "Epoch:    6/25    Loss: 3.7615128922462464\n",
      "\n",
      "Epoch:    6/25    Loss: 3.7880976195335387\n",
      "\n",
      "Epoch:    6/25    Loss: 3.778855128288269\n",
      "\n",
      "Epoch:    6/25    Loss: 3.773331549167633\n",
      "\n",
      "Epoch:    7/25    Loss: 3.730919976609682\n",
      "\n",
      "Epoch:    7/25    Loss: 3.7224085326194762\n",
      "\n",
      "Epoch:    7/25    Loss: 3.702529849052429\n",
      "\n",
      "Epoch:    7/25    Loss: 3.7182808728218077\n",
      "\n",
      "Epoch:    7/25    Loss: 3.733709892272949\n",
      "\n",
      "Epoch:    7/25    Loss: 3.735171681404114\n",
      "\n",
      "Epoch:    7/25    Loss: 3.72502450799942\n",
      "\n",
      "Epoch:    7/25    Loss: 3.736330162525177\n",
      "\n",
      "Epoch:    7/25    Loss: 3.7280127630233766\n",
      "\n",
      "Epoch:    7/25    Loss: 3.731989245891571\n",
      "\n",
      "Epoch:    8/25    Loss: 3.673360639707598\n",
      "\n",
      "Epoch:    8/25    Loss: 3.670231090068817\n",
      "\n",
      "Epoch:    8/25    Loss: 3.6807266750335694\n",
      "\n",
      "Epoch:    8/25    Loss: 3.6778699960708616\n",
      "\n",
      "Epoch:    8/25    Loss: 3.6929133887290955\n",
      "\n",
      "Epoch:    8/25    Loss: 3.676345336437225\n",
      "\n",
      "Epoch:    8/25    Loss: 3.693190454483032\n",
      "\n",
      "Epoch:    8/25    Loss: 3.6983069734573366\n",
      "\n",
      "Epoch:    8/25    Loss: 3.6950914373397827\n",
      "\n",
      "Epoch:    8/25    Loss: 3.7037828903198244\n",
      "\n",
      "Epoch:    9/25    Loss: 3.641012108028507\n",
      "\n",
      "Epoch:    9/25    Loss: 3.6512087874412535\n",
      "\n",
      "Epoch:    9/25    Loss: 3.6367003483772278\n",
      "\n",
      "Epoch:    9/25    Loss: 3.648421998500824\n",
      "\n",
      "Epoch:    9/25    Loss: 3.642700342178345\n",
      "\n",
      "Epoch:    9/25    Loss: 3.6436788516044616\n",
      "\n",
      "Epoch:    9/25    Loss: 3.6660859661102294\n",
      "\n",
      "Epoch:    9/25    Loss: 3.66848739528656\n",
      "\n",
      "Epoch:    9/25    Loss: 3.6742086472511293\n",
      "\n",
      "Epoch:    9/25    Loss: 3.651591440200806\n",
      "\n",
      "Epoch:   10/25    Loss: 3.606377124786377\n",
      "\n",
      "Epoch:   10/25    Loss: 3.6046757345199585\n",
      "\n",
      "Epoch:   10/25    Loss: 3.6097264699935914\n",
      "\n",
      "Epoch:   10/25    Loss: 3.6103647894859314\n",
      "\n",
      "Epoch:   10/25    Loss: 3.621562108516693\n",
      "\n",
      "Epoch:   10/25    Loss: 3.6283263654708864\n",
      "\n",
      "Epoch:   10/25    Loss: 3.6252616991996764\n",
      "\n",
      "Epoch:   10/25    Loss: 3.6307488222122193\n",
      "\n",
      "Epoch:   10/25    Loss: 3.6413395376205444\n",
      "\n",
      "Epoch:   10/25    Loss: 3.634523637294769\n",
      "\n",
      "Epoch:   11/25    Loss: 3.5721885535630062\n",
      "\n",
      "Epoch:   11/25    Loss: 3.574294137477875\n",
      "\n",
      "Epoch:   11/25    Loss: 3.5873904724121095\n",
      "\n",
      "Epoch:   11/25    Loss: 3.583689134120941\n",
      "\n",
      "Epoch:   11/25    Loss: 3.590605392456055\n",
      "\n",
      "Epoch:   11/25    Loss: 3.5918265047073366\n",
      "\n",
      "Epoch:   11/25    Loss: 3.58479860496521\n",
      "\n",
      "Epoch:   11/25    Loss: 3.5955572028160097\n",
      "\n",
      "Epoch:   11/25    Loss: 3.618998469352722\n",
      "\n",
      "Epoch:   11/25    Loss: 3.6128079419136045\n",
      "\n",
      "Epoch:   12/25    Loss: 3.5486041950401557\n",
      "\n",
      "Epoch:   12/25    Loss: 3.5503109188079836\n",
      "\n",
      "Epoch:   12/25    Loss: 3.559941223144531\n",
      "\n",
      "Epoch:   12/25    Loss: 3.552180277347565\n",
      "\n",
      "Epoch:   12/25    Loss: 3.5736610560417175\n",
      "\n",
      "Epoch:   12/25    Loss: 3.5756647696495056\n",
      "\n",
      "Epoch:   12/25    Loss: 3.564755201816559\n",
      "\n",
      "Epoch:   12/25    Loss: 3.5780188455581663\n",
      "\n",
      "Epoch:   12/25    Loss: 3.577943347454071\n",
      "\n",
      "Epoch:   12/25    Loss: 3.573765776157379\n",
      "\n",
      "Epoch:   13/25    Loss: 3.5262537624922916\n",
      "\n",
      "Epoch:   13/25    Loss: 3.5328775053024293\n",
      "\n",
      "Epoch:   13/25    Loss: 3.5289557194709777\n",
      "\n",
      "Epoch:   13/25    Loss: 3.5410811409950256\n",
      "\n",
      "Epoch:   13/25    Loss: 3.5458426637649536\n",
      "\n",
      "Epoch:   13/25    Loss: 3.5470517048835752\n",
      "\n",
      "Epoch:   13/25    Loss: 3.5415273480415346\n",
      "\n",
      "Epoch:   13/25    Loss: 3.5426149129867555\n",
      "\n",
      "Epoch:   13/25    Loss: 3.55139617395401\n",
      "\n",
      "Epoch:   13/25    Loss: 3.5706441535949707\n",
      "\n",
      "Epoch:   14/25    Loss: 3.5026157103664817\n",
      "\n",
      "Epoch:   14/25    Loss: 3.5103406901359557\n",
      "\n",
      "Epoch:   14/25    Loss: 3.5173842735290526\n",
      "\n",
      "Epoch:   14/25    Loss: 3.5097532753944396\n",
      "\n",
      "Epoch:   14/25    Loss: 3.520891508102417\n",
      "\n",
      "Epoch:   14/25    Loss: 3.518722797393799\n",
      "\n",
      "Epoch:   14/25    Loss: 3.5358949694633486\n",
      "\n",
      "Epoch:   14/25    Loss: 3.524609344959259\n",
      "\n",
      "Epoch:   14/25    Loss: 3.524664589881897\n",
      "\n",
      "Epoch:   14/25    Loss: 3.528497277259827\n",
      "\n",
      "Epoch:   15/25    Loss: 3.487209821159231\n",
      "\n",
      "Epoch:   15/25    Loss: 3.485388981819153\n",
      "\n",
      "Epoch:   15/25    Loss: 3.479475655555725\n",
      "\n",
      "Epoch:   15/25    Loss: 3.4856460380554197\n",
      "\n",
      "Epoch:   15/25    Loss: 3.4993635230064393\n",
      "\n",
      "Epoch:   15/25    Loss: 3.5021149015426634\n",
      "\n",
      "Epoch:   15/25    Loss: 3.5003084807395934\n",
      "\n",
      "Epoch:   15/25    Loss: 3.52350554895401\n",
      "\n",
      "Epoch:   15/25    Loss: 3.513862842082977\n",
      "\n",
      "Epoch:   15/25    Loss: 3.508264042377472\n",
      "\n",
      "Epoch:   16/25    Loss: 3.459690733743034\n",
      "\n",
      "Epoch:   16/25    Loss: 3.440024318218231\n",
      "\n",
      "Epoch:   16/25    Loss: 3.4821767535209656\n",
      "\n",
      "Epoch:   16/25    Loss: 3.472396969795227\n",
      "\n",
      "Epoch:   16/25    Loss: 3.482707766056061\n",
      "\n",
      "Epoch:   16/25    Loss: 3.485489525794983\n",
      "\n",
      "Epoch:   16/25    Loss: 3.4720800652503967\n",
      "\n",
      "Epoch:   16/25    Loss: 3.487255733013153\n",
      "\n",
      "Epoch:   16/25    Loss: 3.4921660900115965\n",
      "\n",
      "Epoch:   16/25    Loss: 3.5236644639968873\n",
      "\n",
      "Epoch:   17/25    Loss: 3.444662836371365\n",
      "\n",
      "Epoch:   17/25    Loss: 3.4432944355010986\n",
      "\n",
      "Epoch:   17/25    Loss: 3.446946897506714\n",
      "\n",
      "Epoch:   17/25    Loss: 3.4618360705375673\n",
      "\n",
      "Epoch:   17/25    Loss: 3.4588807468414307\n",
      "\n",
      "Epoch:   17/25    Loss: 3.467527737617493\n",
      "\n",
      "Epoch:   17/25    Loss: 3.4697024359703064\n",
      "\n",
      "Epoch:   17/25    Loss: 3.481428150653839\n",
      "\n",
      "Epoch:   17/25    Loss: 3.4725051865577696\n",
      "\n",
      "Epoch:   17/25    Loss: 3.473727123260498\n",
      "\n",
      "Epoch:   18/25    Loss: 3.4310426840168957\n",
      "\n",
      "Epoch:   18/25    Loss: 3.4319346437454223\n",
      "\n",
      "Epoch:   18/25    Loss: 3.4350480494499207\n",
      "\n",
      "Epoch:   18/25    Loss: 3.4251918454170225\n",
      "\n",
      "Epoch:   18/25    Loss: 3.438065649986267\n",
      "\n",
      "Epoch:   18/25    Loss: 3.4451056489944456\n",
      "\n",
      "Epoch:   18/25    Loss: 3.4520597920417786\n",
      "\n",
      "Epoch:   18/25    Loss: 3.4498885636329653\n",
      "\n",
      "Epoch:   18/25    Loss: 3.4648671641349793\n",
      "\n",
      "Epoch:   18/25    Loss: 3.463255784034729\n",
      "\n",
      "Epoch:   19/25    Loss: 3.3944097755051392\n",
      "\n",
      "Epoch:   19/25    Loss: 3.4210213470458983\n",
      "\n",
      "Epoch:   19/25    Loss: 3.426258209705353\n",
      "\n",
      "Epoch:   19/25    Loss: 3.41080348110199\n",
      "\n",
      "Epoch:   19/25    Loss: 3.4242822923660277\n",
      "\n",
      "Epoch:   19/25    Loss: 3.4293470735549927\n",
      "\n",
      "Epoch:   19/25    Loss: 3.4206723561286925\n",
      "\n",
      "Epoch:   19/25    Loss: 3.441709113121033\n",
      "\n",
      "Epoch:   19/25    Loss: 3.447404511451721\n",
      "\n",
      "Epoch:   19/25    Loss: 3.4508199977874754\n",
      "\n",
      "Epoch:   20/25    Loss: 3.387112282059243\n",
      "\n",
      "Epoch:   20/25    Loss: 3.399129940509796\n",
      "\n",
      "Epoch:   20/25    Loss: 3.3980064396858216\n",
      "\n",
      "Epoch:   20/25    Loss: 3.4175236864089964\n",
      "\n",
      "Epoch:   20/25    Loss: 3.405954596042633\n",
      "\n",
      "Epoch:   20/25    Loss: 3.4101036262512205\n",
      "\n",
      "Epoch:   20/25    Loss: 3.4237644510269165\n",
      "\n",
      "Epoch:   20/25    Loss: 3.4260380783081055\n",
      "\n",
      "Epoch:   20/25    Loss: 3.4176304416656493\n",
      "\n",
      "Epoch:   20/25    Loss: 3.4277150039672852\n",
      "\n",
      "Epoch:   21/25    Loss: 3.3690409637458494\n",
      "\n",
      "Epoch:   21/25    Loss: 3.3752560591697693\n",
      "\n",
      "Epoch:   21/25    Loss: 3.3802209692001344\n",
      "\n",
      "Epoch:   21/25    Loss: 3.377999566078186\n",
      "\n",
      "Epoch:   21/25    Loss: 3.3939227681159974\n",
      "\n",
      "Epoch:   21/25    Loss: 3.394472448348999\n",
      "\n",
      "Epoch:   21/25    Loss: 3.409550895690918\n",
      "\n",
      "Epoch:   21/25    Loss: 3.4181354551315306\n",
      "\n",
      "Epoch:   21/25    Loss: 3.4141567797660826\n",
      "\n",
      "Epoch:   21/25    Loss: 3.4269259557724\n",
      "\n",
      "Epoch:   22/25    Loss: 3.357762947649965\n",
      "\n",
      "Epoch:   22/25    Loss: 3.3663343582153322\n",
      "\n",
      "Epoch:   22/25    Loss: 3.364354770183563\n",
      "\n",
      "Epoch:   22/25    Loss: 3.3689887347221377\n",
      "\n",
      "Epoch:   22/25    Loss: 3.3667144131660462\n",
      "\n",
      "Epoch:   22/25    Loss: 3.3863944830894472\n",
      "\n",
      "Epoch:   22/25    Loss: 3.396412464618683\n",
      "\n",
      "Epoch:   22/25    Loss: 3.387785071849823\n",
      "\n",
      "Epoch:   22/25    Loss: 3.4191043105125427\n",
      "\n",
      "Epoch:   22/25    Loss: 3.403739776611328\n",
      "\n",
      "Epoch:   23/25    Loss: 3.3459042532659082\n",
      "\n",
      "Epoch:   23/25    Loss: 3.3392107191085816\n",
      "\n",
      "Epoch:   23/25    Loss: 3.3634848775863646\n",
      "\n",
      "Epoch:   23/25    Loss: 3.3613835964202883\n",
      "\n",
      "Epoch:   23/25    Loss: 3.3639810371398924\n",
      "\n",
      "Epoch:   23/25    Loss: 3.381359585762024\n",
      "\n",
      "Epoch:   23/25    Loss: 3.357951456069946\n",
      "\n",
      "Epoch:   23/25    Loss: 3.390996919631958\n",
      "\n",
      "Epoch:   23/25    Loss: 3.3819715924263\n",
      "\n",
      "Epoch:   23/25    Loss: 3.3820851912498475\n",
      "\n",
      "Epoch:   24/25    Loss: 3.3343042078036493\n",
      "\n",
      "Epoch:   24/25    Loss: 3.3406594190597536\n",
      "\n",
      "Epoch:   24/25    Loss: 3.343546305656433\n",
      "\n",
      "Epoch:   24/25    Loss: 3.342356472492218\n",
      "\n",
      "Epoch:   24/25    Loss: 3.3447693519592283\n",
      "\n",
      "Epoch:   24/25    Loss: 3.3556096143722534\n",
      "\n",
      "Epoch:   24/25    Loss: 3.3577939734458924\n",
      "\n",
      "Epoch:   24/25    Loss: 3.3744082117080687\n",
      "\n",
      "Epoch:   24/25    Loss: 3.3677697472572325\n",
      "\n",
      "Epoch:   24/25    Loss: 3.375205551624298\n",
      "\n",
      "Epoch:   25/25    Loss: 3.311982202896001\n",
      "\n",
      "Epoch:   25/25    Loss: 3.325809838294983\n",
      "\n",
      "Epoch:   25/25    Loss: 3.3440888757705687\n",
      "\n",
      "Epoch:   25/25    Loss: 3.33032807970047\n",
      "\n",
      "Epoch:   25/25    Loss: 3.3491190528869628\n",
      "\n",
      "Epoch:   25/25    Loss: 3.3442229948043822\n",
      "\n",
      "Epoch:   25/25    Loss: 3.34853244972229\n",
      "\n",
      "Epoch:   25/25    Loss: 3.3648557076454164\n",
      "\n",
      "Epoch:   25/25    Loss: 3.345748482704163\n",
      "\n",
      "Epoch:   25/25    Loss: 3.3626203050613404\n",
      "\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
    "if train_on_gpu:\n",
    "    rnn.cuda()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, epoch, show_every_n_batches)\n",
    "save_filename = os.path.splitext(os.path.basename('./rnn_trained'))[0] + '.pt'\n",
    "torch.save(trained_rnn, save_filename)\n",
    "print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "corresponding-trunk",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T13:25:12.559460Z",
     "iopub.status.busy": "2021-04-08T13:25:12.558918Z",
     "iopub.status.idle": "2021-04-08T13:25:12.564007Z",
     "shell.execute_reply": "2021-04-08T13:25:12.564537Z"
    },
    "papermill": {
     "duration": 0.089124,
     "end_time": "2021-04-08T13:25:12.564713",
     "exception": false,
     "start_time": "2021-04-08T13:25:12.475589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (embedding): Embedding(22805, 256)\n",
      "  (lstm): LSTM(256, 512, num_layers=3, batch_first=True, dropout=0.5)\n",
      "  (fc): Linear(in_features=512, out_features=22805, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-coalition",
   "metadata": {
    "papermill": {
     "duration": 0.080275,
     "end_time": "2021-04-08T13:25:12.725361",
     "exception": false,
     "start_time": "2021-04-08T13:25:12.645086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RNN, LSTM The Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "combined-contribution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T13:25:12.899285Z",
     "iopub.status.busy": "2021-04-08T13:25:12.898106Z",
     "iopub.status.idle": "2021-04-08T13:25:12.900496Z",
     "shell.execute_reply": "2021-04-08T13:25:12.900906Z"
    },
    "papermill": {
     "duration": 0.094763,
     "end_time": "2021-04-08T13:25:12.901030",
     "exception": false,
     "start_time": "2021-04-08T13:25:12.806267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):\n",
    "    \"\"\"\n",
    "    Generate text using the neural network\n",
    "    :param decoder: The PyTorch Module that holds the trained neural network\n",
    "    :param prime_id: The word id to start the first prediction\n",
    "    :param int_to_vocab: Dict of word id keys to word values\n",
    "    :param token_dict: Dict of puncuation tokens keys to puncuation values\n",
    "    :param pad_value: The value used to pad a sequence\n",
    "    :param predict_len: The length of text to generate\n",
    "    :return: The generated text\n",
    "    \"\"\"\n",
    "    rnn.eval()\n",
    "    current_seq = np.full((1, sequence_length), pad_value)\n",
    "    current_seq[-1][-1] = prime_id\n",
    "    predicted = [int_to_vocab[prime_id]]\n",
    "    \n",
    "    for _ in range(predict_len):\n",
    "        if train_on_gpu:\n",
    "            current_seq = torch.LongTensor(current_seq).cuda()\n",
    "        else:\n",
    "            current_seq = torch.LongTensor(current_seq)\n",
    "        hidden = rnn.init_hidden(current_seq.size(0))\n",
    "        output, _ = rnn(current_seq, hidden)\n",
    "        p = F.softmax(output, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu()\n",
    "        top_k = 5\n",
    "        p, top_i = p.topk(top_k)\n",
    "        top_i = top_i.numpy().squeeze()\n",
    "        p = p.numpy().squeeze()\n",
    "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
    "        word = int_to_vocab[word_i]\n",
    "        predicted.append(word)\n",
    "        current_seq = current_seq.cpu().numpy()\n",
    "        current_seq = np.roll(current_seq, -1, 1)\n",
    "        current_seq[-1][-1] = word_i\n",
    "    \n",
    "    gen_sentences = ' '.join(predicted)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
    "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
    "    gen_sentences = gen_sentences.replace('( ', '(')\n",
    "    return gen_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "turkish-bridal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-08T13:25:13.066231Z",
     "iopub.status.busy": "2021-04-08T13:25:13.065592Z",
     "iopub.status.idle": "2021-04-08T13:25:13.689280Z",
     "shell.execute_reply": "2021-04-08T13:25:13.689899Z"
    },
    "papermill": {
     "duration": 0.708635,
     "end_time": "2021-04-08T13:25:13.690082",
     "exception": false,
     "start_time": "2021-04-08T13:25:12.981447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joey hand. ]\n",
      "\n",
      "[scene: central perk, chandler and monica are there. ]\n",
      "\n",
      "rachel: oh, i am so sorry!\n",
      "\n",
      "chandler:(to rachel) you are the most beautiful guy that i was talking about, but...\n",
      "\n",
      "rachel: yeah, i don't know.\n",
      "\n",
      "phoebe: yeah.\n",
      "\n",
      "ross:(to phoebe) oh my god, i know it was a great idea.(she walks over to a table.)\n",
      "\n",
      "rachel:(to phoebe) hey, what did he say?\n",
      "\n",
      "rachel: well, i think it was really hard to be the guy that would be a good thing, but i just wanna say that i don’t have to get back to a big party, and i’m not gonna be in a couple of weeks, so you can see the little bit in the air.\n",
      "\n",
      "ross: yeah, but, i think we can get a job and i have a lot of stuff about that.\n",
      "\n",
      "monica: okay, you guys.\n",
      "\n",
      "rachel: oh, yeah.\n",
      "\n",
      "rachel: okay.\n",
      "\n",
      "rachel: okay.\n",
      "\n",
      "(joey enters.)\n",
      "\n",
      "monica: hey!\n",
      "\n",
      "joey: hey!\n",
      "\n",
      "rachel: hi!(she goes to get it.) i mean, you have to do it.\n",
      "\n",
      "rachel: oh, well, i’m just gonna get a cup of coffee.\n",
      "\n",
      "ross: oh, yeah, i- i know that you can get married.(she takes a bite, and goes to the door and he opens it.) oh god, i love you!\n",
      "\n",
      "rachel: okay.(she goes to the bathroom.)\n",
      "\n",
      "ross: okay.(she goes over and opens the door to his bedroom.)\n",
      "\n",
      "chandler: oh, i can't believe this. i think it’s okay.(they kiss)\n",
      "\n",
      "chandler:(to chandler) you guys are going to take you away.\n",
      "\n",
      "ross:(to phoebe) hey, you know what? i’m gonna go see it.(they both start\n"
     ]
    }
   ],
   "source": [
    "gen_length = 400 # modify the length to your preference\n",
    "prime_word = 'joey' # name for starting the script\n",
    "pad_word = SPECIAL_WORDS['PADDING']\n",
    "generated_script = generate(trained_rnn, vocab_to_int[prime_word], int_to_vocab, pun_dic, vocab_to_int[pad_word], gen_length)\n",
    "print(generated_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-beverage",
   "metadata": {
    "papermill": {
     "duration": 0.081353,
     "end_time": "2021-04-08T13:25:13.853418",
     "exception": false,
     "start_time": "2021-04-08T13:25:13.772065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5500.069591,
   "end_time": "2021-04-08T13:25:15.845393",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-08T11:53:35.775802",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
